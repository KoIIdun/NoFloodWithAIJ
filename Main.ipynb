{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import rdm_helpers as helpers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras import Model\n",
    "#conv2d = tf.keras.layers.Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, id):\n",
    "        return\n",
    "    def fit(self, nodes_data):\n",
    "        nodes_data = pd.Dataframe({})\n",
    "    def getvec(self):\n",
    "        return pd.Dataframe({})\n",
    "    def trained():\n",
    "        if self.trained:\n",
    "            return True\n",
    "        return False\n",
    "    def predict(a, b):\n",
    "        return a, b\n",
    "    def mae():\n",
    "        return 0\n",
    "    def nse():\n",
    "        return 0\n",
    "    \n",
    "class FzcModel():\n",
    "    def __init__(self, gdata, idmap, grev=[]):\n",
    "        self.n = len(gdata)\n",
    "        self.gdata = gdata\n",
    "        self.grev = grev\n",
    "        self.__grevcalc__()\n",
    "        self.idmap = idmap\n",
    "        self.fitmae = [0] * len(gdata)\n",
    "        self.fitnse = [0] * len(gdata)\n",
    "        self.nodes = [Node(idmap[i]) for i in range(len(gdata))]\n",
    "        self.order = helpers.topsorter(gdata)\n",
    "        self.result = 0\n",
    "        self.period = (-1, -1)\n",
    "        pass\n",
    "    def __grevcalc__(self):\n",
    "        if self.grev == [] and self.gdata != []:\n",
    "            self.grev = [[] for i in range(len(self.gdata))]\n",
    "            for i in range(len(self.gdata)):\n",
    "                if len(self.gdata[i]) == 0:\n",
    "                    self.startes.append(i)\n",
    "                for j in range(len(self.gdata[i])):\n",
    "                    self.grev[self.gdata[i][j]].append(i)\n",
    "        print(999)\n",
    "    def refresh(self):\n",
    "        self.fitmae = [0] * len(gdata)\n",
    "        self.fitnse = [0] * len(gdata)\n",
    "        self.nodes = [Node(self.idmap[i]) for i in range(len(self.gdata))]\n",
    "    def trained(self):\n",
    "        for i in self.nodes:\n",
    "            if not i.trained():\n",
    "                return False\n",
    "        return True\n",
    "    def fit(self, log=True):\n",
    "        self.refresh()\n",
    "        say(log, \"-- Fit begin --\")\n",
    "        for i in self.order:\n",
    "            say(log, \"-- Node \" + i + '/' + self.n + ' with id ' + self.idmap[i] + ' fit started --')\n",
    "            self.nodes[i].fit(pd.DataFrame([self.nodes[j].getstage() for j in self.grev]))\n",
    "            \n",
    "#     def refit_node(self, log=True, nodeid=-1, nodenum=-1):\n",
    "#         if self.trained():\n",
    "            \n",
    "#             print(999)\n",
    "    def predict_node(self, period_start, period_end, nodeid=-1, nodenum=-1):\n",
    "        if nodeid != -1:\n",
    "            node = self.nodes[idmap.find(nodeid)]\n",
    "        elif nodenum != -1:\n",
    "            node = idmap[nodeid]\n",
    "        else:\n",
    "            print(\"Неправильный id или num\")\n",
    "            raise ValueError()\n",
    "        if node.trained():\n",
    "        \n",
    "        \n",
    "                return node.predict(period_start, period_end)\n",
    "    def predict(self, period_start, period_end):\n",
    "        self.period = (period_start, period_end)\n",
    "        res = pd.DataFrame({})\n",
    "        for i in self.nodes:\n",
    "            if i.trained() == True:\n",
    "                res[str(self.idmap(i))] = pd.Series(i.predict(period_start, period_end))\n",
    "                self.mae[i] = i.mae()\n",
    "                self.nse[i] = i.nse()\n",
    "            else:\n",
    "                print(\"cannot predict node\" + i + ' with id ' + self.idmap(i) + ' without fit')\n",
    "        res = res.T\n",
    "        self.result = res\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "stations = [6323, 6299, 6265, 6302, 6319]\n",
    "target = 6275\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "stats_dfs = []\n",
    "for s in stations:\n",
    "    d = pd.read_csv(f'./data/hydro/0{s}_daily.csv', index_col='date', engine='python')\n",
    "    d.index = pd.to_datetime(d.index)\n",
    "    stats_dfs.append(d)\n",
    "\n",
    "df = pd.read_csv(f'./data/hydro/0{6275}_daily.csv', index_col='date', engine='python')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "for i in stats_dfs:\n",
    "    s_id = i[\"station_id\"]\n",
    "    df[f'x_{s_id }'] = i['stage_max']\n",
    "\n",
    "X = df.drop('stage_max', axis=1)\n",
    "Y = df['stage_max']\n",
    "\n",
    "X = MinMaxScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class z_model:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def set_parameter(self, lag, nodes, kernel1, kernel2):\n",
    "        inp1 = Input(shape=(nodes, lag, 1))\n",
    "        inp2 = Input(shape=(1, lag, 10))\n",
    "        convup = Conv2D(10, kernel1, padding='valid', input_shape=(nodes, lag, 1))(inp1)\n",
    "        print(convup)\n",
    "        x = layers.Concatenate(axis=1)([inp2, convup])\n",
    "        print(x)\n",
    "        convdown = Conv2D(3, kernel1, padding='same', input_shape=(2, lag, 10))(x)\n",
    "        print(convdown)\n",
    "        flatten = Flatten()(convdown)\n",
    "        output = Dense(lag)(flatten)\n",
    "        self.model = Model(inputs=[inp1, inp2], outputs=output)\n",
    "        return self\n",
    "#     def visualisate():\n",
    "#         plot_model(model, to_file='z_model.png', show_shapes=True)\n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    def model_compile(self):\n",
    "        self.model.compile(\n",
    "            optimizer=\"rmsprop\",\n",
    "            loss='mse',\n",
    "            metrics=['mae'],\n",
    "            loss_weights=None,\n",
    "            weighted_metrics=None,\n",
    "            run_eagerly=None,\n",
    "            steps_per_execution=None,\n",
    "        )\n",
    "        return self\n",
    "    def fit(self):\n",
    "        self.modelModel.fit(\n",
    "            x=X,\n",
    "            y=Y,\n",
    "            batch_size=100,\n",
    "            epochs=5,\n",
    "            verbose=1\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def evalute(self, x_test, y_test):\n",
    "        self.model.evaluate(\n",
    "            x=None,\n",
    "            y=None,\n",
    "            batch_size=None,\n",
    "            verbose=1,\n",
    "            sample_weight=None,\n",
    "            steps=None,\n",
    "            callbacks=None,\n",
    "            max_queue_size=10,\n",
    "            workers=1,\n",
    "            use_multiprocessing=False,\n",
    "            return_dict=False,\n",
    "        )\n",
    "        return self\n",
    "\n",
    "lag = 10\n",
    "nodes = 7\n",
    "z_model = z_model().set_parameter(lag, nodes, (nodes, 1), (2, 1))\n",
    "z_model.get_model().summary()\n",
    "z_model.model_compile()\n",
    "z_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "z_model.fit()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "station_in = []\n",
    "hydro_df = pd.read_csv(data_path + '/0' + str(station_id) + '_daily.csv', index_col = 'date', engine='python')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gdata_path = 'data/graph_data/'\n",
    "data = []\n",
    "with open(gdata_path + \"smez.txt\", 'r') as f:\n",
    "    i = 0\n",
    "    for line in f:\n",
    "        \n",
    "        data.append(line.strip('\\n').split(\" \"))\n",
    "        i += 1\n",
    "        data[i - 1] = list(map(float, data[i - 1]))\n",
    "data_reversed = []\n",
    "with open(gdata_path + \"smez_reversed.txt\", 'r') as f:\n",
    "    i = 0\n",
    "    for line in f:\n",
    "        data_reversed.append([])\n",
    "        #data_reversed[i] = list(map(int, line.strip().split(\",\")[:-1]))\n",
    "        i += 1\n",
    "\n",
    "idmap = pd.read_csv(gdata_path + \"with_elevation.csv\", sep=\",\")[[\"station_id\"]]\n",
    "idmap = idmap.T.apply(lambda x: int(x)).to_list()\n",
    "print(data)\n",
    "FzcModel(data, data_reversed, idmap)\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_in = []\n",
    "hydro_df = pd.read_csv(data_path + '/0' + str(station_id) + '_daily.csv', index_col = 'date', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\api\\_v1\\keras\\layers\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m         \u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mline\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstrip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'\\n'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\" \"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m         \u001B[0mi\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m         \u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmap\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfloat\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m \u001B[0mdata_reversed\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[1;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgdata_path\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;34m\"smez_reversed.txt\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'r'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: could not convert string to float: "
     ]
    }
   ],
   "source": [
    "gdata_path = 'data/graph_data/'\n",
    "data = []\n",
    "with open(gdata_path + \"smez.txt\", 'r') as f:\n",
    "    i = 0\n",
    "    for line in f:\n",
    "        \n",
    "        data.append(line.strip('\\n').split(\" \"))\n",
    "        i += 1\n",
    "        data[i - 1] = list(map(float, data[i - 1]))\n",
    "data_reversed = []\n",
    "with open(gdata_path + \"smez_reversed.txt\", 'r') as f:\n",
    "    i = 0\n",
    "    for line in f:\n",
    "        data_reversed.append([])\n",
    "        #data_reversed[i] = list(map(int, line.strip().split(\",\")[:-1]))\n",
    "        i += 1\n",
    "\n",
    "idmap = pd.read_csv(gdata_path + \"with_elevation.csv\", sep=\",\")[[\"station_id\"]]\n",
    "idmap = idmap.T.apply(lambda x: int(x)).to_list()\n",
    "print(data)\n",
    "FzcModel(data, data_reversed, idmap)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}